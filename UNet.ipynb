{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNoJMcZMZ70C9XAOJ6tx2XF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashika-git/Deep_Learning/blob/main/UNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kjFcf1xw5vt1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class UNet(nn.Module):\n",
        "  def __init__(\n",
        "      self,\n",
        "      in_channels=1, # no of input channels\n",
        "      n_classes=2, # no of output channels\n",
        "      depth=5, # depth of the network\n",
        "      wf=6, # no of filters in the first layer is 2*wf\n",
        "      padding=False, # setting padding=True may result in artifacts\n",
        "      batch_norm=False, # use batchnorm after layers with an activation function\n",
        "      up_mode='upconv' # one of 'upconv' or 'upsample'.'upconv'will use transposed convolutions while 'upsample' will use bilinear upsampling\n",
        "    ):\n",
        "    super(UNet, self).__init__()\n",
        "    assert up_mode in ('upconv', 'upsample')\n",
        "    self.padding = padding\n",
        "    self.depth = depth\n",
        "    prev_channels = in_channels\n",
        "    self.down_path = nn.ModuleList()\n",
        "    for i in range(depth):\n",
        "      self.down_path.append(\n",
        "          UNetConvBlock(prev_channels, 2**(wf + i), padding, batch_norm)\n",
        "      )\n",
        "      prev_channels = 2**(wf + i)\n",
        "\n",
        "\n",
        "    self.up_path = nn.ModuleList()\n",
        "    for i in reversed(range(depth-1)):\n",
        "      self.up_path.append(\n",
        "          UNetUpBlock(prev_channels, 2 ** (wf + i), up_mode, padding, batch_norm)\n",
        "      )\n",
        "      prev_channels = 2 ** (wf + i)\n",
        "\n",
        "    self.last = nn.Conv2d(prev_channels, n_classes, kernel_size=1)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    blocks = []\n",
        "    for i, down in enumerate(self.down_path):\n",
        "      x = down(x)\n",
        "      if i != len(self.down_path) - 1:\n",
        "        blocks.append(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "    for i, up in enumerate(self.up_path):\n",
        "      x = up(x, blocks[-i -1])\n",
        "\n",
        "    return self.last(x)\n",
        "\n",
        "class UNetConvBlock(nn.Module):\n",
        "  def __init__(self, in_size, out_size, padding, batch_norm):\n",
        "    super(UNetConvBlock, self).__init__()\n",
        "    block = []\n",
        "\n",
        "    block.append(nn.Conv2d(in_size, out_size, kernel_size=3, padding=int(padding)))\n",
        "    block.append(nn.ReLU())\n",
        "    if batch_norm:\n",
        "      block.append(nn.BatchNorm2d(out_size))\n",
        "\n",
        "    block.append(nn.Conv2d(in_size, out_size, kernel_size=3, padding=int(padding)))\n",
        "    block.append(nn.ReLU())\n",
        "    if batch_norm:\n",
        "      block.append(nn.BatchNorm2d(out_size))      \n",
        "\n",
        "    self.block = nn.Sequential(*block)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.block(x)\n",
        "    return out   \n",
        "    \n",
        "\n",
        "class UNetUpBlock(nn.Module):\n",
        "  def __init__(self, in_size, out_size, up_mode, padding, batch_norm):\n",
        "    super(UNetUpBlock, self).__init__()\n",
        "    if up_mode == 'upconv':\n",
        "      self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2, stride=2)\n",
        "    elif up_mode == 'upsample':\n",
        "      self.up = nn.Sequential(\n",
        "      nn.Upsample(mode='bilinear', scale_factor=2),\n",
        "      nn.Conv2d(in_size, out_size, kernel_size=1),)\n",
        "\n",
        "      self.conv_block = UNetConvBlock(in_size, out_size, padding, batch_norm)\n",
        "\n",
        "  def center_crop(self, layer, target_size):\n",
        "    _, _, layer_height, layer_width = layer.size()\n",
        "    diff_y = (layer_height - target_size[0]) // 2\n",
        "    diff_x = (layer_width - target_size[1]) // 2\n",
        "    return layer[\n",
        "                 :, :, diff_y : (diff_y + target_size[0]), diff_x : (diff_x + target_size[1])\n",
        "    ]  \n",
        "\n",
        "  def forward(self, x, bridge):\n",
        "    up = self.up(x)\n",
        "    crop1 = self.center_crop(bridge, up.shape[2:])\n",
        "    out = torch.cat([up, crop1], 1)\n",
        "    out = self.conv_block(out)\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = UNet(in_channels=5,n_classes=2, depth=5, wf=3, padding=True, up_mode='upsample').to(device)\n"
      ],
      "metadata": {
        "id": "WAn9O5ftFEF-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4gPXRTu2GyXp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}